<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ming Zhao">
<meta name="dcterms.date" content="2023-07-25">

<title>Neural Networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="Neural_Networks_1_files/libs/clipboard/clipboard.min.js"></script>
<script src="Neural_Networks_1_files/libs/quarto-html/quarto.js"></script>
<script src="Neural_Networks_1_files/libs/quarto-html/popper.min.js"></script>
<script src="Neural_Networks_1_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Neural_Networks_1_files/libs/quarto-html/anchor.min.js"></script>
<link href="Neural_Networks_1_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Neural_Networks_1_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Neural_Networks_1_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Neural_Networks_1_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Neural_Networks_1_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link active" data-scroll-target="#neural-networks">Neural Networks</a>
  <ul class="collapse">
  <li><a href="#tensor-where-it-starts" id="toc-tensor-where-it-starts" class="nav-link" data-scroll-target="#tensor-where-it-starts">Tensor: where it starts</a></li>
  <li><a href="#layers-the-building-blocks-of-deep-learning" id="toc-layers-the-building-blocks-of-deep-learning" class="nav-link" data-scroll-target="#layers-the-building-blocks-of-deep-learning">Layers: the building blocks of deep learning</a></li>
  <li><a href="#activation-functions-beyond-the-linearity" id="toc-activation-functions-beyond-the-linearity" class="nav-link" data-scroll-target="#activation-functions-beyond-the-linearity">Activation functions: beyond the linearity</a></li>
  <li><a href="#loss-function-and-optimizer-less-is-what-we-want" id="toc-loss-function-and-optimizer-less-is-what-we-want" class="nav-link" data-scroll-target="#loss-function-and-optimizer-less-is-what-we-want">Loss function and optimizer: less is what we want</a></li>
  <li><a href="#models-networks-of-layers" id="toc-models-networks-of-layers" class="nav-link" data-scroll-target="#models-networks-of-layers">Models: networks of layers</a></li>
  <li><a href="#anatomy-of-a-neural-network" id="toc-anatomy-of-a-neural-network" class="nav-link" data-scroll-target="#anatomy-of-a-neural-network">Anatomy of a neural network</a></li>
  </ul></li>
  <li><a href="#a-simple-example" id="toc-a-simple-example" class="nav-link" data-scroll-target="#a-simple-example">A Simple Example</a>
  <ul class="collapse">
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">Data Preparation</a></li>
  <li><a href="#network-architecture" id="toc-network-architecture" class="nav-link" data-scroll-target="#network-architecture">Network Architecture</a></li>
  <li><a href="#compilation" id="toc-compilation" class="nav-link" data-scroll-target="#compilation">Compilation</a></li>
  <li><a href="#training-the-network" id="toc-training-the-network" class="nav-link" data-scroll-target="#training-the-network">Training the Network</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Neural Networks</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ming Zhao </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 25, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>
<a href="https://colab.research.google.com/github/ming-zhao/AIML_for_Business/blob/main/Neural_Networks_1.ipynb" target="_blank"><img data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667"></a>
</p>
<section id="neural-networks" class="level1">
<h1>Neural Networks</h1>
<p>Artificial intelligence (AI) has been a subject of intense media hype. Machine learning, deep learning, and AI come up in countless articles, often outside of technology-minded publications.</p>
<p>Artificial intelligence was born in the 1950s, when computer scientists began exploring the possibility of making computers “think.” AI is defined as the effort to automate tasks performed by humans. The field encompasses machine learning and deep learning, but also includes approaches that don’t involve any learning. Symbolic AI, which involves programmers handcrafting a set of rules to manipulate knowledge, was the dominant paradigm in AI until the late 1980s. However, it proved intractable for solving complex problems, leading to the rise of machine learning as a new approach.</p>
<p>The concept of machine learning is a programming paradigm that allows computers to learn on their own how to perform a task by looking at data, instead of relying on human-crafted rules. <span class="math display">\begin{align}
\left.
\begin{aligned}
\text{Rules} \longrightarrow \\
\text{Data} \longrightarrow
\end{aligned} \right|
&amp;\text{Classical programming} \longrightarrow \text{Answer} \\
\\
\left.
\begin{aligned}
\text{Data} \longrightarrow \\
\text{Answer} \longrightarrow
\end{aligned} \right|
&amp;\text{Machine learning} \longrightarrow \text{Rules}
\end{align}</span></p>
<p>Unlike classical programming, where humans input rules and data, and out come answers, machine learning systems are trained by presenting them with many examples relevant to a task, allowing them to find statistical structure in the data and eventually come up with rules for automating the task. Machine learning has become the most popular and successful subfield of AI, driven by faster hardware and larger datasets.</p>
<p>Deep learning is a subfield of machine learning that involves learning successive layers of increasingly meaningful representations from data. It often involves lots of (tens or hundreds) of layers of representations learned automatically from training data via models called <strong>neural networks</strong>. The deep in deep learning isn’t a reference to any kind of deeper understanding achieved by the approach; rather, it stands for this idea of successive layers of representations.</p>
<p>Deep learning is a complex field that requires familiarity with some concepts. Our approach is to build your intuition about these concepts without getting bogged down in overly technical details. This will help you understand the fundamental ideas behind deep learning and how they can be applied to real-world problems.</p>
<section id="tensor-where-it-starts" class="level2">
<h2 class="anchored" data-anchor-id="tensor-where-it-starts">Tensor: where it starts</h2>
<p>Tensors are fundamental to the data representations for neural networks. Another name for the same concept is multidimensional array. The dimensionality of a tensor coincides with the number of indexes used to refer to scalar values within the tensor.</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/tensor.png" width="500">
</center>
<ul>
<li>Scalars: 0 dimensional tensors</li>
<li>Vectors: 1 dimensional tensors</li>
<li>Matrix: 2 dimensional tensors</li>
</ul>
<p>Let’s make data tensors more concrete with real-world examples:</p>
<ul>
<li>Vector data — 2D tensors of shape (samples, features)</li>
<li>Timeseries data or sequence data — 3D tensors of shape (samples, timesteps, features)</li>
<li>Images — 4D tensors of shape (samples, height, width, channels) or (samples, channels, height, width)</li>
<li>Video — 5D tensors of shape (samples, frames, height, width, channels) or (samples, frames, channels, height, width)</li>
</ul>
</section>
<section id="layers-the-building-blocks-of-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="layers-the-building-blocks-of-deep-learning">Layers: the building blocks of deep learning</h2>
<p>A layer in a neural network is a collection of nodes or neurons responsible for learning specific features from input data. Each layer takes one or more input tensors and outputs one or more output tensors, forming a hierarchical structure of learned features.</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/NN_layers.jpg" width="500">
</center>
<p>A crucial aspect of each layer is its set of weights (<span class="math inline">w_i</span> in the simplified representation), which are learned during training and determine the contribution of each input feature to the output. These weights control how much each input feature affects the layer’s output and are adjusted during training to improve the model’s performance. In summary, a neural network layer is a data-processing module that learns meaningful representations of the input data, which are used to make predictions or classifications.</p>
<p>An example of a simple neural network with one input node, two hidden nodes, and one output node can be seen in the included <a href="https://github.com/ming-zhao/ming-zhao.github.io/blob/master/AIML_for_Business/Neural_Networks/data/SimpleNeuralNetwork.xlsx?raw=true">Excel file</a>.</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/simpleNN.png" width="700">
</center>
<p>By varying the input value, the output value exhibits a non-linearity.</p>
</section>
<section id="activation-functions-beyond-the-linearity" class="level2">
<h2 class="anchored" data-anchor-id="activation-functions-beyond-the-linearity">Activation functions: beyond the linearity</h2>
<p>As we have seen, the simplest unit in (deep) neural networks is a linear operation (scaling + offset) followed by an activation function.</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/activation.jpg" width="700">
</center>
<p>where the linear operation is often performed as matrix multiplication.</p>
<p>Activation functions sound complicated, but the most common activation function these days is ReLU, or rectified linear unit. Which again sounds complicated! But all it turns out to be is a function that implements <span class="math inline">max(0,x)</span>, so the result is 0 if the input is negative, or just the input (<span class="math inline">x</span>) if <span class="math inline">x</span> is positive. The graphs illustrate the shape of some commonly used activation functions and how they transform input values to output values.</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/activation2.jpg" width="600">
</center>
<p>Another very important activation function <em>softmax</em>, which is a little more complicated mathematically. Basically it produces a set of values between 0 and 1 that adds up to 1 (probabilities!) and weights the values so it exaggerates differences—that is, it produces one result in a vector higher than everything else. It is often used at the end of a classification network to ensure that that network makes a definite prediction about what class it thinks the input belongs to.</p>
<p>Without activation functions, neural network falls back to being a linear model. Since the layers of linear operations is still a linear operation, the absence of activation functions makes the network unable to learn nonlinear relationships between inputs and outputs. The following are true for the activation functions:</p>
<ul>
<li>They have at least one sensitive range, where nontrivial changes to the input result in a corresponding nontrivial change to the output. This is needed for training.</li>
<li>Many of them have an insensitive (or saturated) range, where changes to the input result in little or no change to the output.</li>
</ul>
</section>
<section id="loss-function-and-optimizer-less-is-what-we-want" class="level2">
<h2 class="anchored" data-anchor-id="loss-function-and-optimizer-less-is-what-we-want">Loss function and optimizer: less is what we want</h2>
<p>A loss function (or cost function) is a function that computes a single numerical value that the learning process will attempt to minimize. The calculation of loss typically involves taking the difference between the desired outputs (labels) for some training samples and the outputs actually produced by the model when fed those samples.</p>
<p>The optimizer determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).</p>
</section>
<section id="models-networks-of-layers" class="level2">
<h2 class="anchored" data-anchor-id="models-networks-of-layers">Models: networks of layers</h2>
<p>A deep learning model is typically composed of multiple layers of interconnected nodes or neurons. In a feedforward neural network (FNN), information flows through the layers in one direction only, with no feedback connections between nodes. This makes FNNs suitable for many classification and regression tasks.</p>
<p>In contrast, a recurrent neural network (RNN) has connections between nodes that can form cycles, allowing the network to retain information and have “memories” of previous inputs. This makes RNNs well-suited for processing sequential data, such as text, speech, and time series data. By maintaining a memory of previous inputs, RNNs can capture long-term dependencies and make predictions based on context.</p>
<p>Overall, the architecture of a deep learning model, whether FNN or RNN, is an important factor in determining its suitability for a particular task.</p>
</section>
<section id="anatomy-of-a-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="anatomy-of-a-neural-network">Anatomy of a neural network</h2>
<p>We consider a simple neural network with 3 hidden layers. It learns from scatter input points of a set of functions, such as <span class="math inline">x^2</span>, <span class="math inline">\sin(x)</span>, <span class="math inline">\text{abs}(x)</span> and <span class="math inline">\text{heaviside}(x)</span>, and outputs the predicted functions.</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/hidden.jpg" width="600">
</center>
<p><a href="#fig-hidden_layers">Figure&nbsp;1</a> displays the features captured by the hidden layers. In other words, the neural network believes that the final curve is a weighted sum of three curves produced by the hidden layers.</p>
<div class="cell" data-outputid="9c8f2d12-7576-47f1-ccea-2fc4d65766e0" data-execution_count="10">
<div class="cell-output cell-output-display">
<div id="fig-hidden_layers" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Neural_Networks_1_files/figure-html/fig-hidden_layers-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Hidden Layers</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="a-simple-example" class="level1">
<h1>A Simple Example</h1>
<p>The MNIST dataset is a popular benchmark dataset for image classification tasks. It consists of 60,000 training images and 10,000 test images of handwritten digits from 0 to 9. Each image is grayscale and has a resolution of 28 <span class="math inline">\times</span> 28 pixels.</p>
<div class="cell" data-outputid="c9913d5e-5bee-44ae-dbad-2975c19e4955" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> mnist</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>(train_images, train_labels), (test_images, test_labels) <span class="op">=</span> mnist.load_data()</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'training images:</span><span class="sc">{}</span><span class="st">, test images:</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(train_images.shape, test_images.shape))</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> showimg(data):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    idx  <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    span <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> data<span class="op">==</span><span class="st">'train'</span>:</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> train_images</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> train_labels</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> data<span class="op">==</span><span class="st">'test'</span>:</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> test_images</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> test_labels</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">2</span>))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        digit <span class="op">=</span> images[idx<span class="op">+</span>i]</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        plt.imshow(digit, cmap<span class="op">=</span>plt.cm.binary)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Index:</span><span class="sc">{}</span><span class="st">, Label:</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(idx<span class="op">+</span>i, labels[idx<span class="op">+</span>i]), fontsize <span class="op">=</span> <span class="dv">12</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>showimg(<span class="st">'train'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>showimg(<span class="st">'test'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>training images:(60000, 28, 28), test images:(10000, 28, 28)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Neural_Networks_1_files/figure-html/cell-3-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Neural_Networks_1_files/figure-html/cell-3-output-3.png" class="img-fluid"></p>
</div>
</div>
<p>We’re using Keras to classify images into their 10 categories (0 through 9).</p>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data Preparation</h2>
<p>Before training, we reshape and scale the image data, and categorically encode the labels</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/mnist_1.jpg" width="700">
</center>
<p>which is executed in python code as follows</p>
<pre class="{python}"><code>train_images_reshape = train_images.reshape((60000, 28 * 28))
train_images_reshape = train_images_reshape.astype('float32') / 255
test_images_reshape = test_images.reshape((10000, 28 * 28))
test_images_reshape = test_images_reshape.astype('float32') / 255

train_labels_cat = to_categorical(train_labels)
test_labels_cat = to_categorical(test_labels)</code></pre>
</section>
<section id="network-architecture" class="level2">
<h2 class="anchored" data-anchor-id="network-architecture">Network Architecture</h2>
<p>The core building block of neural networks is the <em>layer</em>, a data-processing module working as a filter for data. Specifically, layers extract representations out of the data fed into them in a more useful form which is often called features.</p>
<p>Most of deep learning consists of chaining together simple layers that will implement a form of progressive data distillation. A deep-learning model is like a sieve for data processing, made of a succession of increasingly refined data filters the layers.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>network <span class="op">=</span> models.Sequential()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>network.add(layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>,)))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>network.add(layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here, our network consists of a sequence of two densely connected (fully connected) layers.</p>
<center>
<img src="https://github.com/ming-zhao/ming-zhao.github.io/raw/master/AIML_for_Business/Neural_Networks/figures/mnist_2.jpg" width="700">
</center>
<p>The weights of the first layer can be viewed as 512 28x28 filter images. The first layer compares the input images with these 512 filter images and generates 512 filter scores as output.</p>
<p>The second (and last) layer is a 10-way softmax layer. It aggregates the 512 filter scores into 10 probability scores using the softmax activation function. Each score represents the probability that the current digit image belongs to one of the 10 digit classes.</p>
</section>
<section id="compilation" class="level2">
<h2 class="anchored" data-anchor-id="compilation">Compilation</h2>
<p>Before training the network, we need to perform a compilation step by setting up:</p>
<ul>
<li>An optimizer: the mechanism to improve its performance on the training data</li>
<li>A loss function: the measurement of its performance on the training data</li>
<li>Metrics to monitor during training and testing</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>network.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'rmsprop'</span>,</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>                loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>                metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="training-the-network" class="level2">
<h2 class="anchored" data-anchor-id="training-the-network">Training the Network</h2>
<p>We train the network as follows</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>network.fit(train_images_reshape, train_labels_cat, epochs<span class="op">=</span><span class="dv">5</span>, batch_size<span class="op">=</span><span class="dv">128</span>, verbose<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The network will start to iterate on the training data in mini-batch of 128 samples, 5 times over (each iteration over all the training data is called an <em>epoch</em>). At each iteration, the network will compute the gradient of the weights with regard to the loss on the batch, and update the weights accordingly. After these 5 epochs, the network will have performed 2345 = 5 <span class="math inline">\times</span> ceil(60000 <span class="math inline">\div</span> 128) gradient updates.</p>
<p>Batch size impacts learning significantly. If your batch size is big enough, this will provide a stable enough estimate of what the gradient of the full dataset would be. By taking samples from your dataset, you estimate the gradient while reducing computational cost significantly.</p>
<div class="cell" data-outputid="ad4b50a9-d6ad-492a-8e11-86050d4b310b" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> models, layers</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> backend <span class="im">as</span> K</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> to_categorical</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils.data_utils <span class="im">import</span> get_file</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>base <span class="op">=</span> (<span class="st">"https://raw.githubusercontent.com/ming-zhao/ming-zhao.github.io"</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"/master/AIML_for_Business/Neural_Networks/"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model():</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> models.Sequential()</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    model.add(layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>,)))</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    model.add(layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'rmsprop'</span>, loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, metrics<span class="op">=</span>[<span class="st">'acc'</span>])</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    model.fit(train_images_reshape, train_labels_cat, epochs<span class="op">=</span><span class="dv">5</span>, batch_size<span class="op">=</span><span class="dv">128</span>, verbose<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model.save('mnist_simple.h5')</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> mnist</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>(train_images, train_labels), (test_images, test_labels) <span class="op">=</span> mnist.load_data()</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>train_images_reshape <span class="op">=</span> train_images.reshape((<span class="dv">60000</span>, <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>))</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>train_images_reshape <span class="op">=</span> train_images_reshape.astype(<span class="st">'float32'</span>) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>test_images_reshape <span class="op">=</span> test_images.reshape((<span class="dv">10000</span>, <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>))</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>test_images_reshape <span class="op">=</span> test_images_reshape.astype(<span class="st">'float32'</span>) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>train_labels_cat <span class="op">=</span> to_categorical(train_labels)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>test_labels_cat <span class="op">=</span> to_categorical(test_labels)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="co"># model = build_model()</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> models.load_model(get_file(origin<span class="op">=</span>base <span class="op">+</span> <span class="st">'/data/mnist_simple.h5'</span>))</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>test_loss, test_acc <span class="op">=</span> model.evaluate(test_images_reshape, test_labels_cat, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>predicted <span class="op">=</span> np.argmax(model.predict(test_images_reshape, verbose<span class="op">=</span><span class="dv">0</span>), axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="bu">abs</span>(predicted <span class="op">-</span> test_labels)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>misclassified <span class="op">=</span> np.where(result<span class="op">&gt;</span><span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Test accuracy is </span><span class="sc">{}</span><span class="st">%'</span>.<span class="bu">format</span>(<span class="bu">round</span>(test_acc<span class="op">*</span><span class="dv">100</span>,<span class="dv">2</span>)))</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Out of 10000 testing images, </span><span class="sc">{}</span><span class="st"> misclassified images.</span><span class="ch">\n</span><span class="st">'</span>.<span class="bu">format</span>(misclassified.shape[<span class="dv">0</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 512)               401920    
                                                                 
 dense_1 (Dense)             (None, 10)                5130      
                                                                 
=================================================================
Total params: 407,050
Trainable params: 407,050
Non-trainable params: 0
_________________________________________________________________
Test accuracy is 97.91%
Out of 10000 testing images, 209 misclassified images.
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the weights of all layers</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> [layer.get_weights() <span class="cf">for</span> layer <span class="kw">in</span> model.layers]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape the weights into 28x28 images</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>weight <span class="op">=</span> np.reshape(weights[<span class="dv">0</span>][<span class="dv">0</span>], (<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">512</span>))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># print('plot weights of the first layer as a heatmap')</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">16</span>, ncols<span class="op">=</span><span class="dv">32</span>, figsize<span class="op">=</span>(<span class="dv">32</span>,<span class="dv">16</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">16</span>):</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">32</span>):</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        axs[i,j].imshow(weight[:,:,i<span class="op">*</span><span class="dv">32</span><span class="op">+</span>j], cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        axs[i,j].axis(<span class="st">'off'</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-first_layer_heatmap" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Neural_Networks_1_files/figure-html/fig-first_layer_heatmap-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Plot weights of the first layer as a heatmap</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-execution_count="28">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print('plot aggregated weights of both layers as a heatmap')</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Get aggregated weights and reshape</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>weight <span class="op">=</span> (weights[<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">@</span> weights[<span class="dv">1</span>][<span class="dv">0</span>]).reshape(<span class="dv">28</span>, <span class="dv">28</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">10</span>, figsize<span class="op">=</span>(<span class="dv">18</span>,<span class="dv">10</span>))</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    ax.set_title(i)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    im <span class="op">=</span> ax.imshow(weight[:,:,i], cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im, ax<span class="op">=</span>axes, fraction<span class="op">=</span><span class="fl">0.006</span>, pad<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-more_layer_heatmap" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Neural_Networks_1_files/figure-html/fig-more_layer_heatmap-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Plot aggregated weights of both layers as a heatmap</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-execution_count="29">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># print('Examples of misclassified images {}-{}'.format(index, index+4))</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">3</span>))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> misclassified[i<span class="op">+</span>index]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    digit <span class="op">=</span> test_images[idx]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    plt.imshow(digit, cmap<span class="op">=</span>plt.cm.binary)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Predicted:</span><span class="sc">{}</span><span class="st">, Label:</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(predicted[idx], test_labels[idx]), fontsize <span class="op">=</span> <span class="dv">12</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-misclassified" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Neural_Networks_1_files/figure-html/fig-misclassified-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Examples of misclassified images</figcaption>
</figure>
</div>
</div>
</div>
<p>While the aggregated weights plots don’t take into account activation functions and bias terms, they do provide some insight into how the neural network operates. For instance, the center of the 0 image displays strongly negative values, indicating that any color in the center of the image is less likely to be classified as 0.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>